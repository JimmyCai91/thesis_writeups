
\section{Related Work} \label{sec:related-work}
There is a large literature on adaptive optimization under partial
observability which relates to \term submodularity, which can be broadly organized into several different categories. Here, we only review relevant related work that is not already discussed elsewhere in the manuscript.

\subsection{Adaptive Versions of Classic Non-adaptive Optimization Problems} Many approaches consider stochastic generalizations of specific classic non-adaptive optimization problems, such as Set Cover~\citep{goemans06stochastic,liu08near}, Knapsack \citep{dean08approximating,dean05adaptivity} and Traveling Salesman \citep{gupta10approximation}. In contrast, in this paper our goal is to introduce a general problem structure -- \term submodularity -- that unifies a number of adaptive optimization problems. This is similar to how the classic notion of submodularity unifies various optimization problems such as Set Cover, Facility Location, nonadaptive Bayesian Experimental Design, etc.

\subsection{Competitive Online Optimization}  Another active area of
research in sequential optimization is the study of \emph{competitive
  online algorithms}.  
A particularly relevant example is Online Set Cover~\cite{alon09},
where there is a known set system, an arbitrary sequence of elements
is presented to the algorithm, and the algorithm must irrevocably
select sets to purchase such that at all times the purchased sets
cover all elements which have appeared so far.  \citet{alon09}~obtain a
polylogarithmic approximation to this problem, via an online
primal--dual framework which has been profitably applied to many other
problems.  \citet{buchbinder2009} provide a detailed treatment of this
framework.  Note that competitive analysis focuses on worst--case
scenarios.  In contrast, we assume probabilistic information about the
world and optimize for the average case.


\subsection{(Noisy) Interactive Submodular Set Cover}  Recent work
by~\citet{guillory10interactive,guillory2011-noisy-interactive-submod-cover} 
considers a class of adaptive
optimization problems over a family of monotone submodular objectives $\set{f_h
  : h \in \hypotheses}$.  
%
In their problem, one must cover a monotone submodular objective
$f_{\target}$ which
depends on the (initially unknown) target hypothesis $\target \in \hypotheses$, by adaptively
issuing queries and getting responses.  Unlike traditional pool-based
active learning, each query may generate a response from a \emph{set} of
valid responses depending on the target hypothesis.
The reward is calculated by evaluating $f_{\target}$ on the set of (query, response)
pairs observed, and the goal is to obtain some threshold $\quota$ of
objective value at minimum total query cost, where queries may have
nonuniform costs.
In the noisy variant of the problem~~\citep{guillory2011-noisy-interactive-submod-cover}, the set of (query, response)
pairs observed need not be consistent with any hypothesis in $\hypotheses$, and the goal
is to obtain $\quota$ of value for all hypotheses that are ``close''
to being consistent with the observations.
For both variants, \citeauthor{guillory2011-noisy-interactive-submod-cover}
consider the worst-case policy cost, and 
provide greedy algorithms optimizing clever hybrid objective
functions.
They prove an approximation guarantee of $\ln(\quota |\hypotheses|)+1$ for 
integer valued objective functions $\set{f_h}_{h\in \hypotheses}$ in
the noise--free case, and similar logarithmic approximation guarantees
for the noisy case.





\ignore{ %
In their problem, there is a set of hypotheses $\hypotheses$, queries
$\groundset$, responses $\outcomes$.
For each query $e$ and hypothesis $h$, there is a set of valid
responses $e(h) \subseteq \outcomes$ that may be generated by $e$ if $h$
is the true hypothesis.
Each hypothesis $h$ also has an associated monotone submodular objective function
$f_h:2^{\groundset \times \outcomes} \to \NonNegativeIntegers$, 
and the goal is to obtain some quota $\quota$ of reward,
measured by evaluating $f_{\target}$ on the set of (query, response)
pairs observed, 
where $\target$ is the (initially unknown) true hypothesis.  
Hence Interactive Submodular Set Cover combines the problem of learning about the true
hypothesis and covering an objective function depending on
it, in much the same way Adaptive Stochastic Minimum Cost Cover does.
Guillory and Bilmes consider the worst-case policy cost, and 
provide a greedy algorithm optimizing a clever hybrid objective function
with an approximation guarantee of 
$\ln(\quota |\hypotheses|)+1$ for integer valued $\set{f_h}_{h\in \hypotheses}$.
} %

While similar in spirit to this work, there are several significant
differences between the two. 
Guillory and Bilmes focus on worst-case
policy cost, while we focus mainly on average-case policy cost.  
The structure of \term submodularity depends on the prior $\rlzprior$, whereas
there is no such dependence 
in Interactive Submodular Set Cover.
%
This dependence in turn allows us to obtain results, such as 
\thmref{thm:min-set-cover-avg-generalized} for \certifying instances,
whose approximation guarantee does not depend on the number of
realizations in the way that the guarantees for  Interactive
Submodular Set Cover depend on $|\hypotheses|$.  As 
Guillory and Bilmes
prove, the latter dependence
is fundamental under reasonable complexity-theoretic assumptions\footnote{They
  reduce to Set Cover and use the result of \citet{feige98threshold},
  which requires the assumption 
$\NP \nsubseteq \text{DTIME}(n^{\cO(\log\log n)})$, but it suffices to
assume only $\P \neq \NP$ using the Set Cover approximation hardness
result of~\citet{RazS97} instead.}. 
An interesting open problem within the \term submodularity framework
that is highlighted by the work on  Interactive Submodular Set Cover
is to identify useful instance-specific properties that  
are sufficient to improve upon the worst-case approximation guarantee of 
\thmref{thm:min-set-cover-wc-generalized}.



\subsection{Greedy Frameworks for Adaptive Optimization} The paper
that is perhaps 
closest in spirit to this work is the one on Stochastic Depletion problems by \citet{chan09}, who also identify a general class of adaptive optimization problems than can be near-optimally solved using greedy algorithms (which in their setting give a factor 2 approximation). 
However, the similarity is mainly on a conceptual level: The problems and approaches, as well as example applications considered, are quite different. 


\subsection{Stochastic Optimization with Recourse} A class of adaptive
optimization problems  studied extensively in operations research
since \citet{dantzig55linear} is the area of \emph{stochastic optimization with recourse}. Here, an optimization problem, such as Set Cover, Steiner Tree or Facility Location, is presented in multiple stages. At each stage, more information is revealed, but costs of actions increase.  A key difference to the problems studied in this paper is that in these problems, information gets revealed independently of the actions taken by the algorithm. There are general efficient, sampling based (approximate) reductions of multi-stage optimization to the deterministic setting; see, e.g.,\citet{gupta05wednesday}.


\subsection{Bayesian Global Optimization}
Adaptive Stochastic Optimization is also related to the problem of
Bayesian Global Optimization (for a recent
survey of the area, \cf \cite{nandotut}). In Bayesian Global Optimization, the goal is to
adaptively select inputs in order to maximize an unknown function that
is expensive to evaluate (and can possibly only be evaluated using
noisy observations). A common approach that has been successful in
many applications (for a recent application in machine learning, \cf \cite{lizotte07gait}), is to assume a prior distribution, such as a Gaussian process, over the unknown objective function. Several criteria for selecting inputs have been developed, such as the Expected Improvement \citep{ego98} criterion. However, while recently performance guarantees where obtained in the no-regret setting \citep{gruenewaelder10regret,srinivas10gaussian}, we are not aware of any approximation guarantees for Bayesian Global Optimization.


\subsection{Probabilistic Planning} The problem of decision making
under partial observability has also been extensively studied in
stochastic optimal control. In particular, Partially Observable Markov
Decision Processes~\citep{smallwood73optimal}, abbreviated as POMDPs, are a general framework that captures many adaptive optimization problems under partial observability. Unfortunately, solving POMDPs is PSPACE hard \citep{papadimitriou87complexity}, thus typically heuristic algorithms with no approximation guarantees are applied \citep{pineau06anytime,ross08}.
For some special instances of POMDPs related to Multi-armed Bandit
problems, (near-)optimal policies can be found. These include the
(optimal) Gittins-index policy for the classic Multi-armed Bandit problem~\citep{gittins79dynamic} and approximate policies for the Multi-armed Bandit problem with metric switching costs~\citep{guha09multi} and special cases of the Restless Bandit problem \citep{guha09approximation}. The problems considered in this paper can be formalized as POMDPs, albeit with exponentially large state space (where the world state represents the selected items and state/outcome of each item). Thus our results can be interpreted as widening the class of partially observable planning problems that can be efficiently approximately solved.


\subsection{Previous Work by the Authors \& Subsequent Developments}
This manuscript is an extended version of a paper that appeared in the
Conference on Learning Theory \cite{golovin10colt}. 
More recently, \citet{golovin11matroid_arxiv} proved performance
guarantees for the greedy policy for the problem of
maximizing the expected value of a policy under constraints more
complex than simply selecting at most $k$ items.
These include \emph{matroid} constraints, where a policy can only
select independent sets of items and the greedy policy obtains a
$1/2$--approximation for adaptive monotone submodular objectives, and
more generally $p$-\emph{independence system} constraints, where the
greedy policy obtains a $1/(p+1)$--approximation.
\citet{golovin10nips} and, shortly thereafter,~\citet{bellala10modified}, used the adaptive submodularity framework to obtain the first algorithms
with provable (logarithmic) approximation guarantees for the difficult and fundamental problem of 
active learning with persistent noise.
Finally, \citet{golovin11aaai} used adaptive submodularity in the
context of a dynamic conservation planning, and obtain competitiveness guarantees
for an ecological reserve design problem.


%
%
%
%
%
