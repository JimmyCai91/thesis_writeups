\begin{abstract}
Many problems in artificial intelligence require adaptively making a sequence of decisions with uncertain outcomes under partial observability. Solving such stochastic optimization problems is a fundamental but notoriously difficult challenge.  In this paper, we introduce the concept of \emph{\term submodularity}, generalizing submodular set functions to adaptive policies.  We prove that if a problem satisfies this property, a simple adaptive greedy algorithm is guaranteed to be competitive with the optimal policy. In addition to providing  performance guarantees for both stochastic maximization and coverage, \term submodularity can be exploited to drastically speed up the greedy algorithm by using lazy evaluations. We illustrate the usefulness of the concept by giving several examples of \term submodular objectives arising in diverse AI applications including management of sensing resources, viral marketing and active learning. Proving \term submodularity for these problems allows us to recover existing results in these applications as special cases, improve approximation guarantees and handle natural generalizations.
\end{abstract}


%
%
%
%
%
